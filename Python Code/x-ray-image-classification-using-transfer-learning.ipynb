{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#240b36;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px; color:white; text-align: center\"> WELCOME TO MY NOTEBOOK </p>\n</div>","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"\n\n# Introduction\n\n> Our Python project aims to automate the classification of X-ray images by leveraging the capabilities of deep learning. This endeavor has the potential to bring significant benefits to both medical professionals and patients. Our objective is to develop a rapid and precise diagnostic tool for the identification of medical disorders from X-ray pictures by utilizing convolutional neural networks and data augmentation techniques. The initiative aims to establish a connection between technology and healthcare, with the objective of optimizing the diagnosis process.","metadata":{}},{"cell_type":"markdown","source":"### Table of Contents\n\n* [Step 1. Import Necessary Libraries : ](#h1)\n\n* [Step 2. Define dataset paths and Load Images ](#h2)\n\n* [Step 3: Split the Datasets and Generate the DataFram ](#h3)\n\n* [Step-4: View multiple and single randomly Selected Image](#h4)\n\n* [Step 5. Create train/ val split with training ](#h5)\n\n* [Step 6. Build Augmentation layer ](#h6)\n\n* [Step 7. Creating Pipeline for Transfer Learning](#h7)\n\n* [Step 8. Design and Develop Custom CNN Model](#h8)\n\n* [Step 9. Training and Validating Custom CNN Model](#h9)\n\n* [Step 10. Now Plot the Training Loss, Validation Loss, Training Accuracy, Validation Accuracy](#h10)\n\n* [ Conclusion](#h11)\n\n     \n        ## Following this tutorial, you will be able to classify medical image in Python using the transfer learning and popular deep learning tools like TensorFlow and Keras.\n","metadata":{}},{"cell_type":"markdown","source":"# Step-1: Import Necessary Libraries <a class=\"anchor\"  id=\"h1\"></a>\n\n> Import necessary libraries, such as **NumPy, OpenCV, Matplotlib**, and any other relevant packages for image processing and analysis.\n> Verify that you have access to any datasets or images you'll be working with.","metadata":{}},{"cell_type":"code","source":"pip install scikit-plot","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:10:52.573425Z","iopub.execute_input":"2023-10-21T06:10:52.573738Z","iopub.status.idle":"2023-10-21T06:11:04.654424Z","shell.execute_reply.started":"2023-10-21T06:10:52.573714Z","shell.execute_reply":"2023-10-21T06:11:04.653250Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport os\nimport glob \nimport time\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nfrom tensorflow.keras import layers, Sequential\nfrom tensorflow.keras.utils import plot_model\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\nfrom sklearn.metrics import confusion_matrix , ConfusionMatrixDisplay\nfrom scikitplot.metrics import plot_roc\n\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\n","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:11:04.895699Z","iopub.execute_input":"2023-10-21T06:11:04.896027Z","iopub.status.idle":"2023-10-21T06:11:13.834468Z","shell.execute_reply.started":"2023-10-21T06:11:04.895991Z","shell.execute_reply":"2023-10-21T06:11:13.833540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Context-Free Grammar (CFG):\nclass CFG:\n    EPOCHS= 10\n    BATCH_SIZE= 32\n    SEED= 42\n    TF_SEED= 768\n    HEIGHT= 224\n    WIDTH= 224\n    CHANNELS= 3\n    IMAGE_SIZE=(224,224,3)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:12:22.377771Z","iopub.execute_input":"2023-10-21T06:12:22.378529Z","iopub.status.idle":"2023-10-21T06:12:22.383926Z","shell.execute_reply.started":"2023-10-21T06:12:22.378496Z","shell.execute_reply":"2023-10-21T06:12:22.382849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step-2: Define dataset paths and Load Images<a class=\"anchor\"  id=\"h2\"></a>\n\n> *You will set up the paths to your dataset and load the X-ray pictures in Step 2. Before you go any further, make sure that your dataset is organized into the right folders. For example, you could have one directory for each class (like \"normal\" and \"disease\"), and each directory should contain the X-ray images for that class. Here's a simple example of how to use Python and the OpenCV tool to set dataset paths and load images:*","metadata":{}},{"cell_type":"code","source":"DATASET_PATH=\"../input/chest-xray-covid19-pneumonia/Data/\"\nTRAIN_PATH=  \"../input/chest-xray-covid19-pneumonia/Data/train/\"\nTEST_PATH= \"../input/chest-xray-covid19-pneumonia/Data/test/\"","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:13:41.163811Z","iopub.execute_input":"2023-10-21T06:13:41.164425Z","iopub.status.idle":"2023-10-21T06:13:41.168914Z","shell.execute_reply.started":"2023-10-21T06:13:41.164389Z","shell.execute_reply":"2023-10-21T06:13:41.167856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Generate a summary of dataset:\n\nprint(\"DATASET SUMMARY\")\nprint(\"---------------------------------------\")\n\nfor dirpath, dirnames, filenames in os.walk(DATASET_PATH):\n    print(f'there are {len(dirnames)} directories and {len(filenames)} images in {dirpath}')\nprint('\\n---------------------------------------')\n    ","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:14:07.316817Z","iopub.execute_input":"2023-10-21T06:14:07.317195Z","iopub.status.idle":"2023-10-21T06:14:13.027386Z","shell.execute_reply.started":"2023-10-21T06:14:07.317164Z","shell.execute_reply":"2023-10-21T06:14:13.026323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images= glob.glob(f'{TRAIN_PATH}**/*.jpg')\ntest_images= glob.glob(f'{TEST_PATH}**/*.jpg')","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:17:29.423876Z","iopub.execute_input":"2023-10-21T06:17:29.424245Z","iopub.status.idle":"2023-10-21T06:17:29.454937Z","shell.execute_reply.started":"2023-10-21T06:17:29.424213Z","shell.execute_reply":"2023-10-21T06:17:29.454012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_size= len(train_images)\ntest_size= len(test_images)\n\ntotal= train_size+test_size\nprint(f'Total: {total}')","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:18:26.442935Z","iopub.execute_input":"2023-10-21T06:18:26.443628Z","iopub.status.idle":"2023-10-21T06:18:26.448494Z","shell.execute_reply.started":"2023-10-21T06:18:26.443595Z","shell.execute_reply":"2023-10-21T06:18:26.447631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step-3: Split the Datasets and Generate the DataFram<a class=\"anchor\"  id=\"h3\"></a>\n\n> *In Step 3, you will divide your dataset into training, validation, and test sets. You will also make a DataFrame or other data structure to help you organize and handle your data. For this, you can use Python tools like pandas and scikit-learn. How to do it:*","metadata":{}},{"cell_type":"code","source":"def generate_labels(image_paths):\n    return [_.split('/')[-2:][0] for _ in image_paths]\ndef build_df(image_paths, labels):\n    df= pd.DataFrame({\n        'image_path': image_paths,\n        'label': generate_labels(labels)\n    })\n    \n    df['label_encoded'] = df.apply(lambda row: 0 if row.label == 'malignant' else 1, axis=1)\n\n    return df.sample(frac=1, random_state= CFG.SEED).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:18:50.583177Z","iopub.execute_input":"2023-10-21T06:18:50.584007Z","iopub.status.idle":"2023-10-21T06:18:50.591457Z","shell.execute_reply.started":"2023-10-21T06:18:50.583966Z","shell.execute_reply":"2023-10-21T06:18:50.590314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  Build the datafram\n\ntrain_df= build_df(train_images, generate_labels(train_images))\ntest_df= build_df(test_images, generate_labels(test_images))","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:19:34.109820Z","iopub.execute_input":"2023-10-21T06:19:34.110201Z","iopub.status.idle":"2023-10-21T06:19:34.218216Z","shell.execute_reply.started":"2023-10-21T06:19:34.110170Z","shell.execute_reply":"2023-10-21T06:19:34.217523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View frist some sample in training and testing set \n\ntrain_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:19:47.448010Z","iopub.execute_input":"2023-10-21T06:19:47.448352Z","iopub.status.idle":"2023-10-21T06:19:47.678301Z","shell.execute_reply.started":"2023-10-21T06:19:47.448327Z","shell.execute_reply":"2023-10-21T06:19:47.677266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _load(image_path):\n    # Read the image from the file\n    image = tf.io.read_file(image_path)\n    # Decode the image to a uint8 tensor\n    image = tf.io.decode_image(image, channels=3)\n    # Resize the image\n    image = tf.image.resize(image, [CFG.HEIGHT, CFG.WIDTH], method=tf.image.ResizeMethod.LANCZOS3)\n    return image\n","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:20:18.642506Z","iopub.execute_input":"2023-10-21T06:20:18.642882Z","iopub.status.idle":"2023-10-21T06:20:18.648739Z","shell.execute_reply.started":"2023-10-21T06:20:18.642853Z","shell.execute_reply":"2023-10-21T06:20:18.647779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step-4: View multiple and single randomly Selected Image<a class=\"anchor\"  id=\"h4\"></a>\n\n> *In Step 4, you can add the ability to view both a single X-ray picture and a group of randomly chosen images. You can use Python and tools like Matplotlib and OpenCV to do this. This step can be done in this way:*","metadata":{}},{"cell_type":"code","source":" def view_sample(image, label, color_map='rgb',fig_size=(6,4)):\n    plt.figure(figsize=fig_size)\n    if color_map== 'rgb':\n        plt.imshow(image)\n    else:\n        plt.imshow(tf.image.rgb_to_grayscale(image), cmap= color_map)\n    plt.title(f'label:{label}', fontsize= 16)\n    return","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:20:27.648846Z","iopub.execute_input":"2023-10-21T06:20:27.649236Z","iopub.status.idle":"2023-10-21T06:20:27.655190Z","shell.execute_reply.started":"2023-10-21T06:20:27.649205Z","shell.execute_reply":"2023-10-21T06:20:27.653978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#select random sample from train_df\nidx= random.sample(train_df.index.to_list(),1)[0]\n#load the random sample and label\n#sample_image, sample_label= _load(train_df.image_path[idx])\nsample_image = _load(train_df.image_path[idx])\nsample_label = train_df.label_encoded[idx]\n\n#view the random sample colormap= gray\nview_sample(sample_image, sample_label, color_map='gray')","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:20:58.994206Z","iopub.execute_input":"2023-10-21T06:20:58.994971Z","iopub.status.idle":"2023-10-21T06:20:59.344585Z","shell.execute_reply.started":"2023-10-21T06:20:58.994938Z","shell.execute_reply":"2023-10-21T06:20:59.343662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View multiple samples:\ndef view_multiple_samples(df,sample_loader, count=10, color_map='rgb', fig_size=(14,10)):\n    rows= count//5\n    if rows%5>0:\n        rows+=1\n    idx= random.sample(df.index.to_list(), count)\n    fig= plt.figure(figsize=fig_size)\n    \n    for colum,_ in enumerate(idx):\n        plt.subplot(rows,5,colum+1)\n        plt.title(f'Label: {df.label[_]}')\n        if color_map=='rgb':\n            plt.imshow(sample_loader(df.image_path[_]))\n        else:\n            plt.imshow(tf.image.rgb_to_grayscale(sample_loader(df.image_path[_])), cmap=color_map)\n    return","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:21:21.099865Z","iopub.execute_input":"2023-10-21T06:21:21.100714Z","iopub.status.idle":"2023-10-21T06:21:21.107990Z","shell.execute_reply.started":"2023-10-21T06:21:21.100681Z","shell.execute_reply":"2023-10-21T06:21:21.106953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"view_multiple_samples(train_df, _load, count=25, color_map='inferno', fig_size=(15,20))","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:22:27.396259Z","iopub.execute_input":"2023-10-21T06:22:27.396621Z","iopub.status.idle":"2023-10-21T06:22:33.676225Z","shell.execute_reply.started":"2023-10-21T06:22:27.396591Z","shell.execute_reply":"2023-10-21T06:22:33.675158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step-5: Create train/ val split with Training<a class=\"anchor\"  id=\"h5\"></a>\n\n> *In Step 5, you will split the data into training and validation sets. This is an important step in building a machine-learning model. This split lets you use one set of data to train your model (the training set) and a different set to test how well it works (the validation set). Here's how to use Python to make the split:*\n","metadata":{}},{"cell_type":"code","source":"#create train/ val split with training\ntrain_split_idx, val_split_idx,_,_= train_test_split(train_df.index,\n                                                    train_df.label_encoded,\n                                                    test_size= 0.15,\n                                                    stratify=train_df.label_encoded,\n                                                    random_state= CFG.SEED)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:35:52.263427Z","iopub.execute_input":"2023-10-21T06:35:52.264216Z","iopub.status.idle":"2023-10-21T06:35:52.274069Z","shell.execute_reply.started":"2023-10-21T06:35:52.264182Z","shell.execute_reply":"2023-10-21T06:35:52.273148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get new training and validation data\n\ntrain_new_df= train_df.iloc[train_split_idx].reset_index(drop=True)\nval_df= train_df.iloc[val_split_idx].reset_index(drop=True)\n#view shape\ntrain_new_df.shape, val_df.shape\ntrain_new_df","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:37:07.539002Z","iopub.execute_input":"2023-10-21T06:37:07.539933Z","iopub.status.idle":"2023-10-21T06:37:07.556143Z","shell.execute_reply.started":"2023-10-21T06:37:07.539896Z","shell.execute_reply":"2023-10-21T06:37:07.554981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step-6: Build an Augmentation layer<a class=\"anchor\"  id=\"h6\"></a>\n\n> *You can use data augmentation methods on your X-ray image data by building an augmentation layer in Step 6. Adding more data is an important part of deep learning, especially when it comes to picture classification tasks, because it helps the model generalize better. To make this layer, you can use tools like TensorFlow (Keras) or PyTorch. These examples show how to use both frameworks:*","metadata":{}},{"cell_type":"code","source":"#Build Augmentation layer\naugmentation_layer= Sequential([\n    layers.RandomFlip(mode='horizontal_and_vertical',seed=CFG.TF_SEED),\n    layers.RandomZoom(height_factor=(-.01,0.1),width_factor=(-0.1,0.1),seed=CFG.TF_SEED)\n],name= 'augmentation_layer')","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:38:01.324906Z","iopub.execute_input":"2023-10-21T06:38:01.325321Z","iopub.status.idle":"2023-10-21T06:38:01.350051Z","shell.execute_reply.started":"2023-10-21T06:38:01.325286Z","shell.execute_reply":"2023-10-21T06:38:01.349148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show inferno Augmented Image\n\nimage= tf.image.rgb_to_grayscale(sample_image)\nfig,(ax1,ax2)=plt.subplots(1,2,figsize=(8,6))\n#set spacing between subplot\nfig.tight_layout(pad=6.0)\n#view orginal image\nax1.set_title('Orginal image',fontsize=15)\nax1.imshow(image,cmap='inferno')\n#view augmented image\nax2.set_title('Augmented image',fontsize=15)\nax2.imshow(augmentation_layer(image),cmap='inferno')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:40:52.550337Z","iopub.execute_input":"2023-10-21T06:40:52.550703Z","iopub.status.idle":"2023-10-21T06:40:53.208391Z","shell.execute_reply.started":"2023-10-21T06:40:52.550674Z","shell.execute_reply":"2023-10-21T06:40:53.207469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show Gray Augmented Image\n\nimage= tf.image.rgb_to_grayscale(sample_image)\nfig,(ax1,ax2)=plt.subplots(1,2,figsize=(8,6))\n#set spacing between subplot\nfig.tight_layout(pad=6.0)\n#view orginal image\nax1.set_title('Orginal image',fontsize=15)\nax1.imshow(image,cmap='gray')\n#view augmented image\nax2.set_title('Augmented image',fontsize=15)\nax2.imshow(augmentation_layer(image),cmap='gray')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:40:01.402827Z","iopub.execute_input":"2023-10-21T06:40:01.403212Z","iopub.status.idle":"2023-10-21T06:40:02.021545Z","shell.execute_reply.started":"2023-10-21T06:40:01.403178Z","shell.execute_reply":"2023-10-21T06:40:02.020563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step-7: Creating Pipeline for Transfer Learning<a class=\"anchor\"  id=\"h7\"></a>\n\n> *In Step 7, you will use a model that has already been taught to set up a pipeline for transfer learning. Transfer learning lets you use a neural network that has already been trained and adapt it to do what you do better. Using well-known deep learning tools like TensorFlow (Keras) and PyTorch, you can build the pipeline by following these steps:*","metadata":{}},{"cell_type":"code","source":"def encode_labels(labels,encode_depth=2):\n    return tf.one_hot(labels,depth=encode_depth).numpy()\ndef create_pipeline(df,load_function,augment=False,batch_size=32,shuffle=False,cache=None,prefetch=False):\n    #get image path and labels from data_frame\n    image_paths= df.image_path\n    image_labels= encode_labels(df.label_encoded)\n    AUTOTUNE= tf.data.AUTOTUNE\n    #Create dataset with raw data from data frame\n    ds= tf.data.Dataset.from_tensor_slices((image_paths,image_labels))\n    #map augmentation layer and load function to dataset input if augment is true\n    if augment:\n        ds=ds.map(lambda x,y: (augmentation_layer(load_function(x)),y),num_parallel_calls= AUTOTUNE)\n    else:\n        ds= ds.map(lambda x,y: (load_function(x),y),num_parallel_calls= AUTOTUNE)\n    #Applying shuffing based on condion\n    if shuffle:\n        ds= ds.shuffle(buffer_size=1000)\n    #applying batching\n    ds= ds.batch(batch_size)\n    #applying caching based on condion\n    if cache!=None:\n        ds= ds.cache(cache)\n    if prefetch:\n        ds= ds.prefetch(buffer_size= AUTOTUNE)\n    return ds\n","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:41:38.533076Z","iopub.execute_input":"2023-10-21T06:41:38.533953Z","iopub.status.idle":"2023-10-21T06:41:38.543890Z","shell.execute_reply.started":"2023-10-21T06:41:38.533918Z","shell.execute_reply":"2023-10-21T06:41:38.542824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _load(image_path):\n    # Read the image from the file\n    image = tf.io.read_file(image_path)\n    # Decode the image to a uint8 tensor\n    image = tf.io.decode_image(image, channels=3)\n    # Ensure the image has a known shape\n    image.set_shape([CFG.HEIGHT, CFG.WIDTH, 3])\n    # Resize the image\n    image = tf.image.resize(image, [CFG.HEIGHT, CFG.WIDTH], method=tf.image.ResizeMethod.LANCZOS3)\n    return image\n","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:41:57.849580Z","iopub.execute_input":"2023-10-21T06:41:57.850474Z","iopub.status.idle":"2023-10-21T06:41:57.856605Z","shell.execute_reply.started":"2023-10-21T06:41:57.850440Z","shell.execute_reply":"2023-10-21T06:41:57.855279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating Training Pipeline\ntrain_ds= create_pipeline(train_new_df,_load,\n                         augment= True,\n                         batch_size= CFG.BATCH_SIZE,\n                         shuffle=False, prefetch= True)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:42:11.879545Z","iopub.execute_input":"2023-10-21T06:42:11.880319Z","iopub.status.idle":"2023-10-21T06:42:12.288922Z","shell.execute_reply.started":"2023-10-21T06:42:11.880284Z","shell.execute_reply":"2023-10-21T06:42:12.288156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating Test Pipeline\ntest_ds= create_pipeline(test_df,_load,\n                         batch_size= CFG.BATCH_SIZE,\n                         shuffle=False, prefetch= False)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:42:20.230699Z","iopub.execute_input":"2023-10-21T06:42:20.231447Z","iopub.status.idle":"2023-10-21T06:42:20.279412Z","shell.execute_reply.started":"2023-10-21T06:42:20.231412Z","shell.execute_reply":"2023-10-21T06:42:20.278626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating Validation Pipeline\nval_ds= create_pipeline(val_df,_load,\n                         \n                         batch_size= CFG.BATCH_SIZE,\n                         shuffle=False, prefetch= False)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:42:29.526390Z","iopub.execute_input":"2023-10-21T06:42:29.526771Z","iopub.status.idle":"2023-10-21T06:42:29.555798Z","shell.execute_reply.started":"2023-10-21T06:42:29.526739Z","shell.execute_reply":"2023-10-21T06:42:29.554864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step-8: Design and Develop Custom CNN Model <a class=\"anchor\"  id=\"h8\"></a>\n\n> *In Step 8, you will create a unique Convolutional Neural Network (CNN) model for your X-ray picture categorization challenge. This customized CNN model will be developed from the bottom up without using a pre-trained model. Here's how to create your own CNN model with popular deep learning frameworks like TensorFlow (Keras) and PyTorch:*","metadata":{}},{"cell_type":"code","source":"def cnn_model():\n    initializer= tf.keras.initializers.GlorotNormal()\n    cnn_sequential = Sequential([\n        layers.Input(shape=CFG.IMAGE_SIZE, dtype=tf.float32, name='input_image'),\n        layers.Conv2D(16,kernel_size=3, activation='relu', kernel_initializer=initializer),\n        layers.Conv2D(16,kernel_size=3, activation='relu', kernel_initializer=initializer),\n        layers.MaxPool2D(pool_size=2,padding='valid'),\n        \n        \n        layers.Conv2D(8,kernel_size=3, activation='relu', kernel_initializer=initializer),\n        layers.Conv2D(8,kernel_size=3, activation='relu', kernel_initializer=initializer),\n        layers.MaxPool2D(pool_size=2),\n        \n        \n        layers.Flatten(),\n        layers.Dropout(0.2),\n        layers.Dense(128, activation='relu', kernel_initializer=initializer),\n        layers.Dense(2, activation='sigmoid', kernel_initializer=initializer), \n    ], name='cnn_sequential_model')\n    return cnn_sequential\n","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:42:47.602984Z","iopub.execute_input":"2023-10-21T06:42:47.603851Z","iopub.status.idle":"2023-10-21T06:42:47.611559Z","shell.execute_reply.started":"2023-10-21T06:42:47.603815Z","shell.execute_reply":"2023-10-21T06:42:47.610512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create an instance of the model\nmodel_cnn = cnn_model()\nmodel_cnn.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:42:58.139841Z","iopub.execute_input":"2023-10-21T06:42:58.140262Z","iopub.status.idle":"2023-10-21T06:42:58.281282Z","shell.execute_reply.started":"2023-10-21T06:42:58.140228Z","shell.execute_reply":"2023-10-21T06:42:58.280298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step-9: Training and Validating Custom CNN Model <a class=\"anchor\"  id=\"h9\"></a>\n\n> *In Step 9, you will train and test your unique Convolutional Neural Network (CNN) model for classifying X-ray images. Training and validating the model are very important parts of the model creation process. I'll show you how to use popular deep learning tools like TensorFlow (Keras) and PyTorch to train and test your model below:*","metadata":{}},{"cell_type":"code","source":"def train_model(model, num_epochs, callbacks_list, tf_train_data, tf_valid_data=None, shuffling= False):\n    model_history={}\n    if tf_valid_data!=None:\n        model_history= model.fit(tf_train_data,\n                                 epochs= num_epochs,\n                                 validation_data= tf_valid_data,\n                                 validation_steps= int(len(tf_valid_data)),\n                                 callbacks= callbacks_list,\n                                 shuffle= shuffling\n                                )\n    if tf_valid_data==None:\n        model_history= model.fit(tf_train_data,\n                                 epochs= num_epochs,\n                                 callbacks= callbacks_list,\n                                 shuffle= shuffling\n                                )\n    return model_history\n","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:43:10.525349Z","iopub.execute_input":"2023-10-21T06:43:10.525720Z","iopub.status.idle":"2023-10-21T06:43:10.532181Z","shell.execute_reply.started":"2023-10-21T06:43:10.525690Z","shell.execute_reply":"2023-10-21T06:43:10.531178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping_callback= tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                         patience=3,\n                                                         restore_best_weights=True)\n\nreduce_lr_callback= tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                                        patience=2,\n                                                        factor=0.1,\n                                                        verbose=1)\n\nCALLBACKS=[early_stopping_callback, reduce_lr_callback]\nMETRICS=['accuracy']\n","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:43:57.227919Z","iopub.execute_input":"2023-10-21T06:43:57.228317Z","iopub.status.idle":"2023-10-21T06:43:57.234603Z","shell.execute_reply.started":"2023-10-21T06:43:57.228285Z","shell.execute_reply":"2023-10-21T06:43:57.233473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.random.set_seed(CFG.SEED)\nmodel_cnn.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n                 optimizer= tf.keras.optimizers.Adam(learning_rate=0.001),\n                 metrics=METRICS)\n\nprint(f'training{model_cnn.name}.')\nprint(f'Train On{len(train_new_df)} samples, validate on {len(val_df)} samples.')\nprint('----------------------------------------------------------')\ncnn_history= train_model(model_cnn, CFG.EPOCHS, CALLBACKS, train_ds, val_ds, shuffling=False)\n\nmodel_cnn.save(\"Trained Model/xray.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:44:08.630464Z","iopub.execute_input":"2023-10-21T06:44:08.631322Z","iopub.status.idle":"2023-10-21T06:52:05.576094Z","shell.execute_reply.started":"2023-10-21T06:44:08.631286Z","shell.execute_reply":"2023-10-21T06:52:05.575170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_evaluatiion= model_cnn.evaluate(test_ds)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:53:01.275853Z","iopub.execute_input":"2023-10-21T06:53:01.276295Z","iopub.status.idle":"2023-10-21T06:53:12.269349Z","shell.execute_reply.started":"2023-10-21T06:53:01.276260Z","shell.execute_reply":"2023-10-21T06:53:12.268301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model loading\nfrom tensorflow.keras.models import load_model\n\n\nmodel=load_model('../working/Trained Model/xray.h5')","metadata":{"execution":{"iopub.status.busy":"2023-10-21T07:45:53.761219Z","iopub.execute_input":"2023-10-21T07:45:53.761939Z","iopub.status.idle":"2023-10-21T07:45:53.965223Z","shell.execute_reply.started":"2023-10-21T07:45:53.761908Z","shell.execute_reply":"2023-10-21T07:45:53.964156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now Predictions for random image","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.imagenet_utils import preprocess_input\n\n\nimg= image.load_img(\"../input/chest-xray-covid19-pneumonia/Data/test/PNEUMONIA/PNEUMONIA(3421).jpg\",target_size=(224,224))\n\nx= image.img_to_array(img)\nx=x/255\nx= np.expand_dims(x, axis=0)\nimg_data=preprocess_input(x)\nimg_data.shape\npreds= model.predict(x)\npreds= np.argmax(preds, axis=1)\n\nif preds==1:\n    preds=\"The image is Covid19\"\nelif preds==2:\n    preds=\"The image is NORMAL\"\nelse:\n    preds=\"The image is Pneumonia\"\nprint(preds)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T08:20:11.019609Z","iopub.execute_input":"2023-10-21T08:20:11.020007Z","iopub.status.idle":"2023-10-21T08:20:11.094345Z","shell.execute_reply.started":"2023-10-21T08:20:11.019976Z","shell.execute_reply":"2023-10-21T08:20:11.093442Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\nThe image is Covid19\n","output_type":"stream"}]},{"cell_type":"code","source":"preds","metadata":{"execution":{"iopub.status.busy":"2023-10-21T08:18:03.503978Z","iopub.execute_input":"2023-10-21T08:18:03.504911Z","iopub.status.idle":"2023-10-21T08:18:03.510766Z","shell.execute_reply.started":"2023-10-21T08:18:03.504873Z","shell.execute_reply":"2023-10-21T08:18:03.509928Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"'The image is Covid19'"},"metadata":{}}]},{"cell_type":"code","source":"cnn_test_probabilities=model_cnn.predict(test_ds, verbose=1)\ncnn_test_predictions= tf.argmax(cnn_test_probabilities, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:53:32.231640Z","iopub.execute_input":"2023-10-21T06:53:32.232617Z","iopub.status.idle":"2023-10-21T06:53:41.087590Z","shell.execute_reply.started":"2023-10-21T06:53:32.232569Z","shell.execute_reply":"2023-10-21T06:53:41.086509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step-10:  Now Plot the Training Loss, Validation Loss, Training Accuracy, Validation Accuracy <a class=\"anchor\"  id=\"h10\"></a>\n\n> *Step 10 lets you map the training loss, validation loss, training accuracy, and validation accuracy to see how well your custom CNN model is doing while it is being trained. To make these plots, you can use Python tools like Matplotlib. Here are some examples of how to make these plots with TensorFlow (Keras) and PyTorch, two famous deep learning frameworks:*","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef plot_training_curves(history):\n    loss= np.array(history.history['loss'])\n    val_loss= np.array(history.history['val_loss'])\n    \n    accuracy= np.array(history.history['accuracy'])\n    val_accuracy= np.array(history.history['val_accuracy'])\n    \n    epochs= range(len(history.history['loss']))\n    \n    fig, (ax1, ax2)= plt.subplots(1,2,figsize=(10,3))\n    \n    #plot loss\n    ax1.plot(epochs, loss, label='traing_loss', marker='o')\n    \n    ax1.plot(epochs, val_loss, label='val_loss', marker='o')\n    \n    ax1.fill_between(epochs,loss, val_loss, where=(loss>val_loss),color='C0',alpha=0.3,interpolate=True)\n    ax1.fill_between(epochs,loss, val_loss, where=(loss<val_loss),color='C1',alpha=0.3,interpolate=True)\n    \n    ax1.set_title('Loss(Lower Means Better)',fontsize= 16)\n    ax1.set_xlabel('Epochs', fontsize=10)\n    \n    ax1.legend()\n    \n    #plot Accuracy\n    ax2.plot(epochs, accuracy, label='traing_accuracy', marker='o')\n    \n    ax2.plot(epochs, val_accuracy, label='val_accuracy', marker='o')\n    \n    ax2.fill_between(epochs,accuracy, val_accuracy, where=(accuracy>val_accuracy),color='C0',alpha=0.3,interpolate=True)\n    ax2.fill_between(epochs,accuracy, val_accuracy, where=(accuracy<val_accuracy),color='C1',alpha=0.3,interpolate=True)\n    \n    ax2.set_title('Accuracy(Higher Means Better)',fontsize= 16)\n    ax2.set_xlabel('Epochs', fontsize=10)\n    \n    ax2.legend()\n    ","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:54:09.253354Z","iopub.execute_input":"2023-10-21T06:54:09.253764Z","iopub.status.idle":"2023-10-21T06:54:09.265507Z","shell.execute_reply.started":"2023-10-21T06:54:09.253733Z","shell.execute_reply":"2023-10-21T06:54:09.264468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_training_curves(cnn_history)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T06:54:20.815568Z","iopub.execute_input":"2023-10-21T06:54:20.815947Z","iopub.status.idle":"2023-10-21T06:54:21.368034Z","shell.execute_reply.started":"2023-10-21T06:54:20.815914Z","shell.execute_reply":"2023-10-21T06:54:21.367135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion <a class=\"anchor\"  id=\"h11\"></a>\n\n> Finally, whether you utilized a pre-trained transfer learning model or a custom CNN, you've built and trained a deep learning model for X-ray picture categorization. Your main steps are summarized here:\n\n* Preparing the dataset:\n\nClassify your X-ray images (\"normal\" and \"disease\").\nGet the dataset and prepare the photos.\n\n* Splitting Data:\n\nDivide your dataset into training, validation, and test sets to evaluate the model.\n\n* Optional data augmentation:\n\nExpand the training dataset and improve model generalization with data augmentation.\n\n* Choose a Model:\n\nChoose a pre-trained transfer learning model or a custom CNN for classification.\n\n* Model Training:\n\nTrain the chosen model on the training dataset and evaluate it on the validation set.\n\n* Evaluation:\n\nTest the model's accuracy and generalization on another dataset.\n\n* Plotting Results:\n\n1. Visualize training and validation loss and accuracy to analyze model learning.\n   You implemented these stages using TensorFlow (Keras) and PyTorch. After deployment, your model can  classify X-ray pictures into important categories to aid medical diagnosis and assessment.\n\n1. Fine-tuning your model, improving hyperparameters, or integrating it into a medical imaging application may improve your project. Data quality, model architecture, and training will determine the success of your X-ray image classification model. Your model must be monitored and updated to be accurate and reliable in real-world situations.","metadata":{}}]}